# -*- coding: utf-8 -*-
"""NLP-Based Sentiment Analysis of Film Reviews

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eOffPFj120gF2pnXDbajUsxIC_0Vopjy
"""

# Importing necessary libraries
import nltk
from nltk.corpus import movie_reviews
from nltk.classify import NaiveBayesClassifier
from nltk.classify.util import accuracy

# Download the IMDb movie reviews dataset
nltk.download('movie_reviews')

# Load the dataset
positive_reviews = [(movie_reviews.words(fileid), 'pos') for fileid in movie_reviews.fileids('pos')]
negative_reviews = [(movie_reviews.words(fileid), 'neg') for fileid in movie_reviews.fileids('neg')]

# Split the dataset into training and testing sets
train_set = positive_reviews[:800] + negative_reviews[:800]
test_set = positive_reviews[800:] + negative_reviews[800:]

# Define a feature extractor function
def get_features(words):
    return dict([(word, True) for word in words])

# Apply the feature extractor to the dataset
train_features = [(get_features(words), category) for (words, category) in train_set]
test_features = [(get_features(words), category) for (words, category) in test_set]

# Train a Naive Bayes classifier
classifier = NaiveBayesClassifier.train(train_features)

# Calculate accuracy on the test set
import nltk
nltk.download('punkt')

accuracy_score = accuracy(classifier, test_features)

print(f'Accuracy: {accuracy_score * 100:.2f}%')

# Test the classifier on a sample sentence
sample_sentence = "The movie was really great!"
sample_features = get_features(nltk.word_tokenize(sample_sentence))
sentiment = classifier.classify(sample_features)

print(f'Sentiment: {sentiment}')

# Import necessary libraries
import nltk
from nltk.corpus import movie_reviews
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Download the IMDb movie reviews dataset
nltk.download('movie_reviews')

# Load the dataset
positive_reviews = [" ".join(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids('pos')]
negative_reviews = [" ".join(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids('neg')]

# Create labels for the reviews (1 for positive, 0 for negative)
labels = [1] * len(positive_reviews) + [0] * len(negative_reviews)

# Combine positive and negative reviews
all_reviews = positive_reviews + negative_reviews

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)

# Transform the reviews into TF-IDF features
tfidf_features = tfidf_vectorizer.fit_transform(all_reviews)

# Initialize SVM classifier
svm_classifier = SVC()

# Split data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.2, random_state=42)

# Train SVM classifier
svm_classifier.fit(X_train, y_train)

# Predict labels on test set
y_pred = svm_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")